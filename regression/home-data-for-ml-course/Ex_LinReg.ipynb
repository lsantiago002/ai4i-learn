{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13d7db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI Singapore\n",
    "# Regression 2 Exercise\n",
    "# Exercise: Building a Regression job template\n",
    "\n",
    "# 1. Import required libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import datetime as d\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea3dcb",
   "metadata": {},
   "source": [
    "Information on Data\n",
    "https://www.kaggle.com/c/home-data-for-ml-course/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b4eba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Classes and Functions\n",
    "def display_df_info(df_name, my_df, v=False):\n",
    "    \"\"\"Convenience function to display information about a dataframe\"\"\"\n",
    "\n",
    "    print(\"Data: {}\".format(df_name))\n",
    "    print(\"Shape (rows, cols) = {}\".format(my_df.shape))\n",
    "    print(\"First few rows...\")\n",
    "    print(my_df.head())\n",
    "\n",
    "    # Optional: Display other optional information with the (v)erbose flag\n",
    "    if v:\n",
    "        print(\"Dataframe Info:\")\n",
    "        print(my_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba6cf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetAge(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom Transformer: Calculate age (years only) relative to current year. Note that \n",
    "    the col values will be replaced but the original col name remains. When the transformer is \n",
    "    used in a pipeline, this is not an issue as the names are not used. However, if the data \n",
    "    from the pipeline is to be converted back to a DataFrame, then the col name change should \n",
    "    be done to reflect the correct data content.\"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self,X):\n",
    "        current_year = int(d.datetime.now().year)\n",
    "\n",
    "        \"\"\"TASK: Replace the 'YearBuilt' column values with the calculated age (subtract the \n",
    "        current year from the original values). -----------Done\n",
    "        \"\"\"\n",
    "        X['Age'] = current_year - X['YearBuilt']\n",
    "        # X.drop(['YearBuilt'], axis=1 , inplace=True) \n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff0cbe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\lorei\\\\anaconda3\\\\ai4i\\\\sup3-regression\\\\home-data-for-ml-course'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92d9e245",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: Raw Input\n",
      "Shape (rows, cols) = (1460, 72)\n",
      "First few rows...\n",
      "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
      "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
      "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
      "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
      "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
      "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
      "\n",
      "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
      "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
      "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
      "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
      "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
      "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
      "\n",
      "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
      "0        0       0       2    2008        WD         Normal    208500  \n",
      "1        0       0       5    2007        WD         Normal    181500  \n",
      "2        0       0       9    2008        WD         Normal    223500  \n",
      "3        0       0       2    2006        WD        Abnorml    140000  \n",
      "4        0       0      12    2008        WD         Normal    250000  \n",
      "\n",
      "[5 rows x 72 columns]\n",
      "Data: Features before Transform\n",
      "Shape (rows, cols) = (1460, 8)\n",
      "First few rows...\n",
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "0     8450       2003       856       854         2             3   \n",
      "1     9600       1976      1262         0         2             3   \n",
      "2    11250       2001       920       866         2             3   \n",
      "3     9550       1915       961       756         1             3   \n",
      "4    14260       2000      1145      1053         2             4   \n",
      "\n",
      "   TotRmsAbvGrd HouseStyle  \n",
      "0             8     2Story  \n",
      "1             6     1Story  \n",
      "2             6     2Story  \n",
      "3             7     2Story  \n",
      "4             9     2Story  \n",
      "Dataframe Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1460 entries, 0 to 1459\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   LotArea       1460 non-null   int64 \n",
      " 1   YearBuilt     1460 non-null   int64 \n",
      " 2   1stFlrSF      1460 non-null   int64 \n",
      " 3   2ndFlrSF      1460 non-null   int64 \n",
      " 4   FullBath      1460 non-null   int64 \n",
      " 5   BedroomAbvGr  1460 non-null   int64 \n",
      " 6   TotRmsAbvGrd  1460 non-null   int64 \n",
      " 7   HouseStyle    1460 non-null   object\n",
      "dtypes: int64(7), object(1)\n",
      "memory usage: 91.4+ KB\n",
      "None\n",
      "Results on Test Data\n",
      "####################\n",
      "RMSE: 42645.12\n",
      "R2 Score: 0.73938\n",
      "Data: Actual vs Predicted Comparison\n",
      "Shape (rows, cols) = (438, 5)\n",
      "First few rows...\n",
      "      actual      predicted          diff      abs_diff  percentage_diff\n",
      "892   154500  133706.182295 -20793.817705  20793.817705       -15.551875\n",
      "1105  325000  311498.947448 -13501.052552  13501.052552        -4.334221\n",
      "413   115000  108758.777437  -6241.222563   6241.222563        -5.738592\n",
      "522   159000  163646.770058   4646.770058   4646.770058         2.839512\n",
      "1036  315500  247463.968793 -68036.031207  68036.031207       -27.493308\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \n",
    "    # DATA INPUT\n",
    "    ############\n",
    "    file_path = \"train_csv_EDA.csv\" #TASK: Modify to path of file ---- Done\n",
    "    input_data = pd.read_csv(file_path) # TASK: Read in the input csv file using pandas ---- Done\n",
    "    display_df_info(\"Raw Input\", input_data)\n",
    "\n",
    "    # Seperate out the outcome variable from the loaded dataframe\n",
    "    output_var_name = 'SalePrice'\n",
    "    output_var = input_data[output_var_name]\n",
    "    input_data.drop(output_var_name, axis=1, inplace=True)\n",
    "\n",
    "    # DATA ENGINEERING / MODEL DEFINITION\n",
    "    #####################################\n",
    "\n",
    "    # Subsetting the columns: define features to keep\n",
    "    feature_names = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', \n",
    "                     'TotRmsAbvGrd', 'HouseStyle'] # TASK: Define the names of the columns to keep\n",
    "    features = input_data[feature_names]\n",
    "    display_df_info('Features before Transform', features, v=True)\n",
    "\n",
    "    # Create the pipeline ...\n",
    "    # 1. Pre-processing\n",
    "    # Define variables made up of lists. Each list is a set of columns that will go through the same data transformations.\n",
    "    # numerical_features = [col for col in features.columns if features.dtypes[col] != 'object'] # TASK: Define numerical column names\n",
    "    # categorical_features = [col for col in features.columns if col not in numerical_features] # TASK: Define categorical column names\n",
    "    \n",
    "    \n",
    "    categorical_features = features.select_dtypes(include=\"object\").columns\n",
    "    numerical_features = features.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "    \"\"\"TASK:\n",
    "    Define the data processing steps (transformers) to be applied to the numerical features in the dataset.\n",
    "\n",
    "    At a minimum, use 2 transformers: GetAge() and one other. Combine them using make_pipeline() or Pipeline()\n",
    "    \"\"\"\n",
    "    int_transformer = Pipeline(steps = [\n",
    "        ('imputer', SimpleImputer(strategy = 'median')),\n",
    "        ('scaler', StandardScaler())\n",
    "        ])\n",
    "\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "        ])\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('ints', int_transformer, numerical_features),\n",
    "            ('cat', cat_transformer, categorical_features)\n",
    "            ])\n",
    "\n",
    "\n",
    "    # preprocess = make_column_transformer(\n",
    "    #     # (\"\"\"TASK: Define transformers\"\"\", numerical_features),\n",
    "    #     (StandardScaler(), GetAge(), numerical_features),\n",
    "    #     (OneHotEncoder(), categorical_features)\n",
    "    # )\n",
    "    \n",
    "    # 2. Combine pre-processing with ML algorithm\n",
    "    # model = make_pipeline(\n",
    "    #     preprocess,\n",
    "    #     LinearRegression() # TASK : replace with ML algorithm from scikit ---Done\n",
    "    # )\n",
    "    reg = LinearRegression()\n",
    "    model = Pipeline(steps=[\n",
    "        ('preprocessor', preprocess),\n",
    "        ('regression', reg)\n",
    "        ])\n",
    "\n",
    "    # TRAINING\n",
    "    ##########\n",
    "    # Train/Test Split\n",
    "    \"\"\"TASK:\n",
    "    Split the data in test and train sets by completing the train_test_split function below. \n",
    "    Define a random_state value so that the experiment is repeatable.\n",
    "    \"\"\"\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, output_var, test_size=0.3, random_state=42) # TASK: Complete the code ---Done\n",
    "\n",
    "    # Train the pipeline\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Optional: Train with cross-validation and/or parameter grid search\n",
    "\n",
    "    # # Perform 10-fold CV\n",
    "    # cvscores_10 = cross_val_score(reg, features, output_var, cv = 10)\n",
    "    # print(\"CV score mean: {}\".format(np.mean(cvscores_10)))\n",
    "\n",
    "    # SCORING/EVALUATION\n",
    "    ####################\n",
    "    # Fit the model on the test data\n",
    "    pred_test = model.predict(x_test)    # y_pred = predicted\n",
    "    \n",
    "    # Display the results of the metrics\n",
    "    \"\"\"TASK: /Done\n",
    "    Calculate the RMSE and Coeff of Determination between the actual and predicted sale prices. \n",
    "        \n",
    "    Name your variables rmse and r2 respectively.\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, pred_test))  # y_test = actual\n",
    "    # print(\"pred_test type: {}\".format(type(pred_test)))\n",
    "    r2 = r2_score(y_test, pred_test)\n",
    "\n",
    "\n",
    "    print(\"Results on Test Data\")\n",
    "    print(\"####################\")\n",
    "    print(\"RMSE: {:.2f}\".format(rmse))\n",
    "    print(\"R2 Score: {:.5f}\".format(r2))\n",
    "    \n",
    "    # Compare actual vs predicted values\n",
    "    \"\"\"TASK: /Done\n",
    "    Create a new dataframe which combines the actual and predicted Sale Prices from the test dataset. You\n",
    "    may also add columns with other information such as difference, abs diff, %tage difference etc.\n",
    "    \n",
    "    Name your variable compare\n",
    "    \"\"\"\n",
    "    data = { 'actual': y_test, 'predicted':pred_test } # build dataset\n",
    "\n",
    "    compare = pd.DataFrame(data) # make it a new DataFrame\n",
    "    # add a column for difference, abs diff, %tage diff: diff, abs_diff, percentage_diff\n",
    "    compare['diff'] = compare['predicted'] - compare['actual']\n",
    "    compare['abs_diff'] = compare['diff'].abs()\n",
    "    compare['percentage_diff'] = (compare['diff'] / compare['predicted']) * 100\n",
    "\n",
    "    display_df_info('Actual vs Predicted Comparison', compare)\n",
    "\n",
    "    # Save the model \n",
    "    with open('my_model_lr.joblib', 'wb') as fo:  \n",
    "        joblib.dump(model, fo)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d83735f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "01a55ce7111c1fe1c2ac875901ffdada59983eb3c9a97afd7f0e7d1a4dad1f6a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
